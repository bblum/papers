%
% LaTeX template for prepartion of submissions to PLDI'15
%
% Requires temporary version of sigplanconf style file provided on
% PLDI'15 web site.
%
\documentclass[pldi]{sigplanconf-pldi15}

%
% the following standard packages may be helpful, but are not required
%
\usepackage{SIunits}            % typset units correctly
\usepackage{courier}            % standard fixed width font
\usepackage[scaled]{helvet} % see www.ctan.org/get/macros/latex/required/psnfss/psnfss2e.pdf
\usepackage{url}                  % format URLs
\usepackage{listings}          % format code
\usepackage{amsthm}          % format code
\usepackage{enumitem}      % adjust spacing in enums
\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage{algpseudocode}
\usepackage{graphicx}
%\usepackage{setspace}
\usepackage[colorlinks=true,allcolors=blue,breaklinks,draft=false]{hyperref}   % hyperlinks, including DOIs and URLs in bibliography
% known bug: http://tex.stackexchange.com/questions/1522/pdfendlink-ended-up-in-different-nesting-level-than-pdfstartlink
\newcommand{\doi}[1]{doi:~\href{http://dx.doi.org/#1}{\Hurl{#1}}}   % print a hyperlinked DOI
%\doublespacing


\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}

\begin{document}

%
% any author declaration will be ignored  when using 'plid' option (for double blind review)
%

% TODO: Don't forget to run e.g. s/\\quicksand /\\quicksand~/
\newcommand\landslide{\textsc{Landslide}}
\newcommand\quicksand{\textsc{Quicksand}}
\newcommand\simics{\textsc{Simics}}
\newcommand{\sect}[1]{\S #1}
\newcommand\hilight[2]{\color{#1}#2\color{black}}
\definecolor{olivegreen}{RGB}{0,127,0}
\definecolor{brickred}{RGB}{192,0,0}

% TODO: Finalize these numbers.
\newcommand\numthrlibs{79}
\newcommand\numpintoses{79}
\newcommand\numstudence{158} % total pintoses plus p2s

\title{Soundness Proof for Eliminating Malloc-Recycle Data Races in Stateless Model Checking}
\authorinfo{Ben Blum}{Carnegie Mellon University}{bblum@cs.cmu.edu}

\maketitle
\begin{abstract}
In our paper we show the effectiveness of combining dynamic data-race detection \cite{eraser,hybriddatarace} with stateless model checking \cite{verisoft,dpor}.
Our approach involves adding new state spaces to explore each time a new data-race candidate is found.
Despite many powerful reduction techniques, the state spaces are still exponentially sized,
so any way to avoid exploring some in advance is obviously beneficial.
We prove that for the special case of {\em malloc-recycle} false positives, it is safe to eliminate these immediately upon discovering them, without bothering to explore their associated state spaces.


This document is supplemental material to our main paper; we assume the reader is already familiar with our motivation and terminology.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Definitions}

\subsection{Stateless model checking terms}

\begin{definition}[Transition]
A sequence of instructions executed by the program between two preemption points (PPs).
\label{def:transition}
\end{definition}
Our model checker provides the invariant that each transition's instructions are associated with exactly one thread. (That is, the set of PPs always includes all thread switches.)

\begin{definition}[Must-happen-before (MHB)]
	Given two transitions $A$ and $B$, we say $A$ MHB $B$ if $B$ cannot be reordered to occur before $A$.
\end{definition}
All transitions of the same thread are trivially MHB-related.
Two transitions $A$ and $B$ of different threads MHB if some synchronization event in $A$ causes $B$ to become runnable while it was previously blocked. Such synchronization events include {\tt thread\_create}, {\tt cond\_signal}, {\tt sem\_post}, but {\em not} {\tt mutex\_lock} or {\tt mutex\_unlock}.
% FIXME: Address concern about using blocking sync primitives, eg sem or rwlock, in a mutex like fashion.
% FIXME: Even though MHB(T1_0, T1_1) and MHB(T1_1, T2_0), then still not necessarily MHB(T1_0, T2_0).

Note how our {\em must}-happen-before relation differs from the conventional definition of happens-before (``observed to happen before'') \cite{lamport-clocks}.
Our use of MHB matches the ``limited happens-before'' used in \cite{hybriddatarace} and \cite{tsan};
the advantage of this over pure-happens-before detectors in producing fewer false negatives is well-argued in those prior works\footnote{
Because pure-happens-before data race detectors avoid false positives altogether, they would have no trouble avoiding our malloc-recycle false positives.
However, as prior work has shown, they miss many other bugs involving unprotected variables accessed alternately before and after mutex-protected critical sections.
Indeed, because most concurrent malloc implementations are protected by a lock, our malloc-recycle false positives are indistinguishable from such false negatives.
}.

\begin{definition}[Shared memory conflict]
A pair of memory accesses between two threads where at least one of them is a write.
\end{definition}
Intuitively, the behaviour of a program could change by reordering two transitions only if they contain a memory conflict.

\begin{definition}[Dynamic Partial Order Reduction (DPOR)]
	A state-space search algorithm for stateless model checkers,
	guaranteed to reorder transitions of two threads
	iff they have a shared memory conflict and are not related by MHB \cite{dpor}.
	\label{def:dpor}
\end{definition}

\subsection{Data race and other memory terms}

\begin{definition}[Data race]
A shared memory conflict where furthermore:
\begin{itemize}
	\item The intersection of both threads' locksets is empty (i.e., the threads do not hold the same lock during each access), and
	\item The threads' transitions are not related by MHB.
\end{itemize}
\end{definition}

The same as in the paper, we distinguish between data-race {\em candidates} and data-race {\em bugs}.
In this proof we are concerned solely with candidates, and judging whether they are true data races or false positives.
It is up to \quicksand, outside the scope of this proof, to decide whether they are benign or buggy.

\begin{definition}[False positive data race]
	An apparent data race that cannot be observed in the opposite order from what was actually executed.
\end{definition}

False positives are caused when some data dependency based on some other shared state, invisible to the data-race analysis,
changes some variable values when the threads are reordered, such that the memory addresses no longer collide.

\begin{definition}[Malloc-recycle data race]
	A data race where the address is contained in some heap-allocated memory, and between the two accesses, that memory was passed to free() and returned again by a subsequent malloc().
\end{definition}

Figures~\ref{fig:recycle} and \ref{fig:recycle-bug} show an example.
In the case of malloc-recycle false positives, the allocation heap is the ``other shared state'' mentioned in the previous definition, and malloc's return value is the variable value that changed.

\begin{definition}[Use after free]
	Any read or write to heap memory which was once allocated, but no longer is.
\end{definition}

These can immediately be identified as failures by a MC which tracks allocation state.
%Most commonly this refers to accesses to a region already freed, but for brevity we also include
% TODO: need heap block overrun?

\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& \multicolumn{2}{c}{\texttt{struct x \{ int foo; int baz; \} *x;}} \\
	& \multicolumn{2}{c}{\texttt{struct y \{ int bar; \} *y;~~~~~~~~~~}} \\
	\\
	& Thread 1 & Thread 2 \\
	1 & \texttt{\hilight{brickred}{x1->foo = ...;}} & \\
	2 & \texttt{\hilight{olivegreen}{free}(x);} \\
	3 & & \texttt{// x's memory recycled} \\
	4 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	5 & & \texttt{// ...initialize...}\\
	6 & & \texttt{publish(y);} \\
	7 & & \texttt{\hilight{brickred}{y->bar = ...;}} \\
\end{tabular}
\caption{False-positive malloc-recycle pattern. This is the common case for which we avoid creating new state spaces.}
\label{fig:recycle}
\end{figure}
\section{Intuition}

In summary, we are proving that if a malloc-recycle-pattern data race is a true race, rather than a false positive,
then DPOR is guaranteed to ``reorder away the free and re-malloc''.
In other words, DPOR's exploration will eventually interleave threads in such a way that the malloc-recycle pattern will disappear,
while the access pair remains for the data-race detector to find, as shown in Figure~\ref{fig:recycle-goal}.
Hence, in the same state space where the malloc-recycle data race was found, if it's a true race, the same race will also appear without the recycle pattern.
So if that race hides a failure bug (assertion, segfault, etc.), Iterative Deepening will still be led to the necessary preemption point to find that bug.


\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& Thread 1 & Thread 2 \\
	1 & \texttt{publish(x1);} & \\
	2 & & \texttt{x2 = get\_published\_x();} \\
	3 & \texttt{\hilight{brickred}{x1->foo = ...;}} & \\
	4 & \texttt{\hilight{olivegreen}{free}(x);} \\
	5 & & \texttt{// x's memory recycled} \\
	6 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	7 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
\end{tabular}
\caption{Adversarial program which fits the malloc-recycle pattern, but nevertheless contains a true race.}
\label{fig:recycle-bug}
\end{figure}

\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& Thread 1 & Thread 2 \\
	1 & \texttt{publish(x);} & \\
	2 & & \texttt{x2 = get\_published\_x();} \\
	3 & & \texttt{// x not free, so malloc's} \\
	4 & & \texttt{// return value changes!} \\
	5 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	6 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
	7 & \texttt{\hilight{brickred}{x1->foo = ...;}} & \\
	8 & \texttt{\hilight{olivegreen}{free}(x);} \\
\end{tabular}
\caption{Goal interleaving, which reorders the adversarial program's threads away from the pattern, while the data race remains.}
\label{fig:recycle-goal}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Assumptions}

{\bf Maximal state space.}
We assume the model checker has all static/hard-coded PPs enabled during this state space exploration,
and that we are not limited by a pressing CPU budget.
Further, we assume that the static PPs include all lock/unlock/trylock operations on mutexes (or whatever other low-level locks are used) and also all higher-level sync primitives which can cause MHB (either directly, or because they are built on top of mutexes).

Using only a subset of PPs or aborting early due to time-out could each ruin our ability to reach the goal interleaving.
However, Iterative Deepening aims to test the most important interleavings with the time available,
so in the case of not enough time, our point here is that continuing the current state space fits that goal best.

{\bf Low overhead.}
We assume the model checker can identify malloc-recycle data races with little or no overhead beyond what's already associated with data race detection.
Our MC already tracks the heap state, so we implement this check for free with a simple generation counter.

{\bf Malloc is a magic black box.}
We assume the malloc implementation is correct (e.g., it won't double-allocate blocks), although we don't assume any implementation details such as any tendency to reuse blocks or allocate adjacent ones.
%particular allocation pattern regarding adjacency/coalescing/reuse.
In fact, in our experiments we instruct our MC to ignore all potential PPs which might be inserted on malloc's internal mutex;
in essence treating it as a ``magic primitive'', because we are not interested in verifying its implementation.
Furthermore, we configured DPOR to ignore the internal heap metadata accesses
when tracking shared memory conflicts to achieve greater state space reduction
(i.e., if the only consequence of reordering two transitions is malloc returning different addresses, we consider them independent).
%for the purpose of avoiding malloc-only shared memory conflicts.
This is not without consequences; see section~\ref{sec:owned}.

{\bf Sharing heap addresses.}
Finally, we assume that the only way the program can obtain heap addresses is through the return value of malloc().
Because we are testing C programs, any bizarre violations of this assumption are technically possible,
but should you wish to check for bugs like this,
we would recommend a data-flow analysis which is much cheaper than model checking anyway.

For Section \ref{sec:proof}, we further assume a malloced block's address cannot be obtained through arithmetic on the address of a different block; in Section \ref{sec:owned} we show how to account for this case by relaxing the ``black box'' assumption.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Proof}
\label{sec:proof}

Though Figures~\ref{fig:recycle-bug} and \ref{fig:recycle-goal} show example programs, they do not capture all possible cases of how a true data race can fit the malloc-recycle pattern.
We proceed by establishing what must be true of any such program, then casing on the ambiguous possibilities, and showing that PPs will exist where we need them to reorder the threads.

For certain, there must be an access in one thread, followed by a free and malloc (we'll call them ``middle free'' and ``middle malloc''), each possibly from either thread, followed by an access from the other.
If the data race is not a false positive, then the second access must not change locations based on the middle malloc's return value.
WLOG, we say that thread 1 (T1) does the first access, called {\tt x1}, and thread 2 (T2) does the second, {\tt x2}.

\begin{lemma}
	If DPOR will reorder {\tt x2} to before {\tt x1}, then a non-malloc-recycle data race or a use-after-free bug will be identified.
	\label{lem:reorder}
\end{lemma}
\begin{proof}
By case on which threads the middle free and middle malloc came from.
\begin{itemize}
	\item T1 free, T2 malloc (as shown in Figure~\ref{fig:recycle-bug}). The malloc will go with {\tt x2} to before the free, and because the allocation of concern has not been freed yet, will return a different value. Hence {\tt x1} and {\tt x2} will be in the same allocation; hence the race is not malloc-recycle anymore.
	\item T1 free, T1 malloc. Same as above, but the malloc does not move. The middle malloc will still recycle the memory, but {\tt x2} now occurs before then, being in the same allocation.
	\item T2 free, T2 malloc. Both the free and re-malloc will occur before either {\tt x1} or {\tt x2}. The memory will be recycled and both accesses will appear to be in the later allocation.
	\item T2 free, T1 malloc. The free gets reordered earlier, the malloc stays put, and the accesses go in between. This will be a use-after-free bug.
\end{itemize}
If either the middle free or middle malloc came from a third thread, the case is the same as if it belonged to T1.
\end{proof}

By our last assumption, there must also be an ``original malloc'' which allocated the heap block to begin with.
We must ask, which thread did the malloc which returned {\tt x1}'s address in the first place?
Because of our last assumption, we know that the other thread must obtain that address through some communication mechanism (which we'll reason about later).

\subsection{T2 originally malloced x}

\begin{lemma}[Greedo]
	If T2 originally malloced the block containing {\tt x}, DPOR will reorder the threads.
	\label{lem:greedo}
\end{lemma}
\begin{proof}
Because T1 had the first access, there was a thread switch between the original malloc and {\tt x1}, as well as between {\tt x1} and {\tt x2}. By Definition~\ref{def:transition}, each switch will be a PP.
By Definition~\ref{def:dpor}, DPOR will reorder {\tt x2} to before {\tt x1}. Lemma~\ref{lem:reorder} finishes.
\end{proof}

This lemma also applies if a third thread was responsible for this malloc, as there would still be a thread switch in the same spot.

\subsection{T1 originally malloced x}

\begin{lemma}[Han]
	If T1 originally malloced the block containing {\tt x}, DPOR will reorder the threads.
	\label{lem:han}
\end{lemma}

\begin{proof}
This is the hard case. We must prove there is a PP... TODO
\end{proof}


%We will also say that T1 does the initial malloc which first returns {\tt x1}'s address; although certainly T2 or even a third thread could have malloced it, that would involve a thread switch to thread 1, and hence a PP by Definition~\ref{def:transition}.
%As we will see, the main challenge of the proof is showing that enough PPs will exist at appropriate points, so adding more PPs by considering other threads for the initial malloc can only make the proof easier.

\subsection{Conclusion}

\begin{theorem}[Soundness of eliminating malloc-recycle races]
	If a malloc-recycle data race is not a false positive, DPOR will reorder threads such that either the same accesses will still race without fitting the malloc-recycle pattern, or a use-after-free bug will be reported immediately.
\end{theorem}
\begin{proof}
	Between Lemmas \ref{lem:greedo} and \ref{lem:han}, all cases of possible program structure are covered.
\end{proof}


\section{Heap overruns}
\label{sec:owned}

Actually, there is another way to share the allocation's address without T1 and T2 communicating outside of {\tt x1}/{\tt x2}: one thread overruns a {\em different} heap block which happened to be adjacent to the one containing {\tt x1}/{\tt x2} (call them the ``neighbour block'' and ``real block'' respectively).
Figure~\ref{fig:overrun} shows an example.
Heap overrun bugs are quite serious \cite{eternal-war}, so we do not wish to exclude them from our model.
So we must also consider the cases where T1 mallocs the real block and T2 overflows a neighbour, and vice versa.


\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& Thread 1 & Thread 2 \\
	1 & & \texttt{z = malloc(42);} \\
	2 & & \texttt{// TODO bounds check??} \\
	3 & & \texttt{x2 = \&z[50];} \\
	4 & \texttt{x1 = malloc(...);} & \\
	5 & \texttt{\hilight{brickred}{x1->foo = ...;}} & \\
	6 & \texttt{\hilight{olivegreen}{free}(x);} \\
	7 & & \texttt{// x's memory recycled} \\
	8 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	9 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
\end{tabular}
\caption{Final possibility for how T2 can share T1's allocation address, and probably a security vulnerability to boot!}
\label{fig:overrun}
\end{figure}

\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& Thread 1 & Thread 2 \\
	1 & & \texttt{z = malloc(42);} \\
	2 & & \texttt{// TODO bounds check??} \\
	3 & & \texttt{x2 = \&z[50];} \\
	4 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	5 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
	6 & \texttt{x1 = malloc(...);} & \\
	7 & \texttt{\hilight{brickred}{x1->foo = ...;}} & \\
	8 & \texttt{\hilight{olivegreen}{free}(x);} \\
\end{tabular}
\caption{Without a PP between lines 4 and 5 of Figure~\ref{fig:overrun}, this is the only alternate interleaving DPOR would explore. Because the mallocs have been reordered, they may no longer collide, which wrongly appears to be a false positive.}
\label{fig:overrun-notenough}
\end{figure}


\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& Thread 1 & Thread 2 \\
	1 & & \texttt{z = malloc(42);} \\
	2 & & \texttt{// TODO bounds check??} \\
	3 & & \texttt{x2 = \&z[50];} \\
	4 & \texttt{x1 = malloc(...);} & \\
	5 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	6 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
	7 & \texttt{\hilight{brickred}{x1->foo = ...;}} & \\
	8 & \texttt{\hilight{olivegreen}{free}(x);} \\
\end{tabular}
\caption{Goal interleaving of Figure~\ref{fig:overrun}. To ensure collision, the sequence of malloc calls which produce {\tt x1} and {\tt x2} must not be disrupted.}
\label{fig:overrun-goal}
\end{figure}


{\bf Being Owned.}
The second best thing I can think to do is say, put "speculative" PPs on the end of malloc, and enable them only when that malloc is involved in a FRM situtation. Then, measure among all FRM sitations (gs12642/landslide/pldi/p2-live/frms) how much bigger the state spaces get (and whether that affects our bugfinding ability/cputimes).


The first best thing I can think to do is to argue that this case doesn't disrupt soundness because the original model we were working with was already unsound. If the other interleaving ("the best dpor could find") occurred first, dpor would not identify a memory conflict at all, and would not reorder to find the original interleaving (with the FRM false pos) at all. this is because dpor ignores malloc's internal accesses from the shm conflict relation.

what we are trying to prove is that, if we START WITH a sound dpor, and add this FRM-elimination, you end up with a sound dpor. BUT, the original one was not sound with respect to this bug to begin with.

then you can simply point out that if you want dpor to be sound wrt this bug, you have to put a PP on the end of malloc (other spots, beginning of malloc and either end of free, are not needed), and also make the shm conflix relation account for the way malloc reordering can change the address collision issue.

is that good enough?

if not,
Hopefully you can think of another way to resolve this later.


\begin{lemma}
	asdfa
	\label{lem:leia} % "there is another"
\end{lemma}

%\subsection{Malloc with internal mutexes}
%
%First we assume that the malloc implementation is guarded by
%
%
%Mario man is very very hunger from not having enough plumming jobs, so his Quest for Eat and Dollars.
%
%
%\subsection{Malloc as a magic primitive}
%
%Actually, regardless of malloc's internal synchronization details, in virtually all cases we wish to avoid unnecessary PPs on its boundaries during MC, because unlike other uses of mutexes, it doesn't indicate any concurrent behaviour is going on.
%Much like the {\tt mx\_test} in our paper, the malloc implementation could itself be tested for concurrency bugs, but in all other cases,
%we drastically reduce the state space size by assuming it is correct and avoiding PPs on it, treating it instead as a ``magic primitive''.
%
%Hence, we provide another proof that does not require
%
%%\cite{landslide} % uncomment post-double-blind review
%
%This spells QED so we are done.

\bibliographystyle{abbrvnat}
\bibliography{citations}{}
\end{document}
