\section{Proof of malloc-recycle soundness}
\label{sec:proof}

We seek to prove that ignoring malloc-recycle data races cannot cause DPOR + Iterative Deepening to miss a bug that could be found by using the malloc-recycle race as a PP. Hence, our soundness statement is as follows:

\begin{theorem}[Soundness of eliminating malloc-recycle races]
	If a malloc-recycle data race is not a false positive, DPOR will reorder threads such that either the same accesses will still race without fitting the malloc-recycle pattern, or a use-after-free bug will be reported immediately.
\end{theorem}

Though Figures~\ref{fig:recycle-bug} and \ref{fig:recycle-goal} show example programs, they do not capture all possible cases of how a true data race can fit the malloc-recycle pattern.
We proceed by establishing what must be true of any such program, then casing on the ambiguous possibilities, and showing that PPs will exist where we need them to reorder the threads.

For certain, there must be an access in one thread, followed by a free and malloc (we'll call them ``middle free'' and ``middle malloc''), each possibly from either thread, followed by an access from the other.
If the data race is not a false positive, then the second access must not change locations based on the middle malloc's return value.
WLOG, we say that thread 1 (T1) does the first access, called {\tt x1}, and thread 2 (T2) does the second, {\tt x2}.

\begin{lemma}
	If DPOR will reorder {\tt x2} to before {\tt x1}, and the location of access {\tt x2} doesn't change,
	then a non-malloc-recycle data race or a use-after-free bug will be identified.
	\label{lem:reorder}
\end{lemma}
\begin{proof}
By case on which threads the middle free and middle malloc came from.
\begin{itemize}
	\item T1 free, T2 malloc (as shown in Figure~\ref{fig:recycle-bug}). The malloc will go with {\tt x2} to before the free, and because the allocation of concern has not been freed yet, will return a different value. Hence {\tt x1} and {\tt x2} will be in the same allocation; hence the race is not malloc-recycle anymore.
	\item T1 free, T1 malloc. Same as above, but the malloc does not move. The middle malloc will still recycle the memory, but {\tt x2} now occurs before then, being in the same, older, allocation.
	\item T2 free, T2 malloc. Both the free and re-malloc will occur before either {\tt x1} or {\tt x2}. The memory will be recycled and both accesses will appear to be in the later allocation.
	\item T2 free, T1 malloc. The free gets reordered earlier, the malloc stays put, and the accesses go in between. This will be a use-after-free bug.
\end{itemize}
If either the middle free or middle malloc came from a third thread, the case is the same as if it belonged to T1.
\end{proof}

The keen reader might ask here, what if T1 contains some extra spurious malloc calls (not related to {\tt x1}) that affect what T2's malloc returns after being reordered?
However, these could at best either cause {\tt x}'s memory to be recycled slightly differently (not affecting the proof), or not at all (which simply changes some cases to be immediate use-after-frees).
%If such a malloc could affect {\tt x2}, the data race would be a false positive after all.
In general, adding spurious mallocs that could affect {\tt x1} or {\tt x2} could only convert the program back into a false-positive scenario;
and adding more spurious synchronization events could only make it more easy to find PPs we need to trigger the reordering.
So, WLOG, we say that the only relevant events are the ones we mention explicitly.

By our last assumption, there must also be an ``original malloc'' which allocated the heap block to begin with.
We must ask, which thread did the malloc which returned {\tt x1}'s address in the first place?
Because of our last assumption, we know that the other thread must obtain that address through some communication mechanism (which we'll reason about later).

\subsection{T2 originally malloced x}

\begin{lemma}[Greedo]
	If T2 originally malloced the block containing {\tt x}, DPOR will reorder the threads to uncover a non-malloc-recycle race or a use-after-free bug.
	\label{lem:greedo}
\end{lemma}
\begin{proof}
Because T1 had the first access, there was a thread switch between the original malloc and {\tt x1}, as well as between {\tt x1} and {\tt x2}. By Definition~\ref{def:transition}, each switch will be a PP.
By Definition~\ref{def:dpor}, DPOR will reorder {\tt x2} to before {\tt x1},
and because T1 is not involved in the logic determining {\tt x2}, the access's location stays the same.
Lemma~\ref{lem:reorder} finishes.
\end{proof}

This lemma also applies if a third thread was responsible for this malloc, as there would still be a thread switch in the same spot.

\subsection{T1 originally malloced x}

\begin{lemma}[Han]
	If T1 originally malloced the block containing {\tt x}, DPOR will reorder the threads to uncover a non-malloc-recycle race or a use-after-free bug.
	\label{lem:han}
\end{lemma}

\begin{proof}
We must guarantee there will be a PP during T1 before its {\tt x1} access, but after whatever action it took to communicate the heap address to T2\footnote{
Note why we assert the publish action must come before {\tt x1}: otherwise, T2 couldn't be reordered to race {\tt x2} with {\tt x1} before T1 communicated the address, and it would be a false positive after all.}.

%\begin{figure}[t]
%	\small
%\begin{tabular}{rll}
%	& Thread 1 & Thread 2 \\
%	0 & \texttt{lock();} & \\
%	1 & \texttt{publish(x1);} & \\
%	3 & \texttt{\hilight{brickred}{x1->foo = ...;}} & \\
%	4 & \texttt{\hilight{olivegreen}{free}(x1);} \\
%	0 & \texttt{unlock();} & \\
%	0 & & \texttt{lock();} \\
%	2 & & \texttt{x2 = get\_published\_x();} \\
%	0 & & \texttt{unlock();} \\
%	5 & & \texttt{// x's memory recycled} \\
%	6 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
%	7 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
%\end{tabular}
%\caption{If the locksets are the same in T1 during publish and x1, you can't avoid the data race on publish+get.}
%\label{fig:recycle-bug}
%\end{figure}

We ask: was there a synchronization event (unlock or message-pass) between the publish action and {\tt x1}?
If so, then by the maximal state space assumption, the event will be a PP, and we are done.
If not, then  T1's lockset during publish will be the same as the lockset during {\tt x1} (and the fact that there is no MHB cannot change).
For T1's publish to reach T2, they must access the same memory ({\em outside} of the block containing {\tt x1}; T2 doesn't have that yet),
which we'll call {\tt p}.
By the previous two statements, {\tt p} must be a data race of its own.
%(whether by writing {\tt x}'s address directly into the shared memory, or by sharing a pointer to a data structure containing {\tt x} -- doesn't matter which)

\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& Thread 1 & Thread 2 \\

	%1 & \texttt{p1 = \hilight{olivegreen}{malloc}(...);} & \\
	1 & \texttt{\hilight{brickred}{p1->ptr = x1;}} & \\
	2 & \texttt{publish(p1);} & \\
	3 & \texttt{\hilight{olivegreen}{free}(p1);} & \\
	4 & \texttt{\hilight{brickred}{x1->foo = ...;}} & \\
	5 & \texttt{\hilight{olivegreen}{free}(x1);} \\


	6 & & \texttt{p2 = get\_published\_p();} \\
	7 & & \texttt{\hilight{commentblue}{// p's memory recycled}} \\
	8 & & \texttt{q = \hilight{olivegreen}{malloc}(sizeof *q);} \\
	9 & & \texttt{\hilight{brickred}{x2 = p2->ptr;}} \\


	10 & & \texttt{\hilight{commentblue}{// x's memory recycled}} \\
	11 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	12 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
\end{tabular}
\caption{If the accesses used to publish {\tt x}'s address are a data race, their PPs may also be eliminated under the malloc-recycle pattern. Induction on the pointer structure leading to {\tt x} handles this case.}
\label{fig:induction}
\end{figure}

Because it's possible for {\tt p} to {\em also} be a malloc-recycle data race,
as shown in Figure~\ref{fig:induction},
we do not necessarily get the PP for free here.
In this case we need to prove that DPOR will likewise reorder any intermediate malloc-recycle pattern to generate the PP we need\footnote{
In \quicksand, data race PPs are not used immediately, but rather generate new state spaces to explore in the future. Anyway, under the maximal state space assumption, we will get to it eventually.}.
We handle this with induction on T2's pointer chain leading to {\tt x}.

\newcommand\publish[1]{{\tt p}$_{#1}$}
\begin{itemize}
	\item For the base case, the publish location \publish{0} is either in global memory, or shared directly using synchronization.
		Non-heap memory data races are not subject to the malloc-recycle pattern, so will always get a data-race PP,
		and use of synchronization always gets a PP in the maximal state space.
	\item For the inductive step, a pointer \publish{n} is published in some heap memory \publish{n-1}\texttt{->ptr},
		and we assume that however \publish{n-1} is shared to T2,
		there will be a PP there
		% where \publish{n-1} is shared
		sufficient to make the \publish{n-1}\texttt{->ptr} access not malloc-recycle after DPOR.
		%DPOR will test some interleaving in which T1's
		Hence a data race PP will be generated on the \publish{n-1}\texttt{->ptr} access.
		Hence by Definition~\ref{def:dpor} and Lemma~\ref{lem:reorder},
		DPOR will reorder T1's and T2's subsequent accesses to \publish{n} sufficiently to place a PP on them.
		% i.e., so that the p_n access no longer appears to be malloc-recycle.
\end{itemize}

Hence, even if the accesses by which T1 shares {\tt x} with T2 appear in a different malloc-recycle pattern,
a PP will be identified on the publish location {\tt p}.
Hence by Definition~\ref{def:dpor} DPOR will reorder T2's execution to just after the publish action.
% XXX: Landslide does not do this! It only puts a PP immediately *before* the access. That's incompatible with this, which needs you to put one both before and after.
As long as T2's execution occurs after the publish, it will receive the same value for its {\tt x2}, so the location of the data race does not change.
Lemma~\ref{lem:reorder} finishes.
%Hence for any type of publish action, there will be a PP between it and {\tt x1}, hence DPOR will reorder {\tt x2} to before {\tt x1} (without changing the address at which {\tt x2} occurs), and Lemma~\ref{lem:reorder} finishes.


\end{proof}


%We will also say that T1 does the initial malloc which first returns {\tt x1}'s address; although certainly T2 or even a third thread could have malloced it, that would involve a thread switch to thread 1, and hence a PP by Definition~\ref{def:transition}.
%As we will see, the main challenge of the proof is showing that enough PPs will exist at appropriate points, so adding more PPs by considering other threads for the initial malloc can only make the proof easier.

\subsection{Conclusion}

\setcounter{theorem}{2}
\begin{theorem}[Soundness of eliminating malloc-recycle races]
	If a malloc-recycle data race is not a false positive, DPOR will reorder threads such that either the same accesses will still race without fitting the malloc-recycle pattern, or a use-after-free bug will be reported immediately.
\end{theorem}
\begin{proof}
	Between Lemmas \ref{lem:greedo} and \ref{lem:han}, all cases of possible program structure are covered.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Heap overruns}
\label{sec:owned}

Actually, there is another way to share the allocation's address without T1 and T2 communicating outside of {\tt x1}/{\tt x2}: one thread overruns a {\em different} heap block which happened to be adjacent to the one containing {\tt x1}/{\tt x2} (call them the ``neighbour block'' and ``real block'' respectively).
Figure~\ref{fig:overrun} shows an example.
Heap overrun bugs are quite serious \cite{eternal-war}, so we do not wish to exclude them from our model.
So we must also consider the cases where T1 mallocs the real block and T2 overflows a neighbour, and vice versa.


\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& Thread 1 & Thread 2 \\
	1 & & \texttt{z = malloc(42);} \\
	2 & & \texttt{\hilight{commentblue}{// TODO bounds check??}} \\
	3 & & \texttt{x2 = \&z[50];} \\
	4 & \texttt{x1 = malloc(...);} & \\
	5 & \texttt{\hilight{brickred}{x1->foo = ...;}} & \\
	6 & \texttt{\hilight{olivegreen}{free}(x1);} \\
	7 & & \texttt{\hilight{commentblue}{// x's memory recycled}} \\
	8 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	9 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
\end{tabular}
\caption{Final possibility for how T2 can share T1's allocation address, and probably a security vulnerability to boot!}
\label{fig:overrun}
\end{figure}

\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& Thread 1 & Thread 2 \\
	1 & & \texttt{z = malloc(42);} \\
	2 & & \texttt{\hilight{commentblue}{// TODO bounds check??}} \\
	3 & & \texttt{x2 = \&z[50];} \\
	4 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	5 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
	6 & \texttt{x1 = malloc(...);} & \\
	7 & \texttt{\hilight{brickred}{x1->foo = ...;}} & \\
	8 & \texttt{\hilight{olivegreen}{free}(x1);} \\
\end{tabular}
\caption{Without a PP between lines 4 and 5 of Figure~\ref{fig:overrun}, this is the only alternate interleaving DPOR would explore. Because the mallocs have been reordered, they may no longer collide, which wrongly appears to be a false positive.}
\label{fig:overrun-notenough}
\end{figure}


\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& Thread 1 & Thread 2 \\
	1 & & \texttt{z = malloc(42);} \\
	2 & & \texttt{\hilight{commentblue}{// TODO bounds check??}} \\
	3 & & \texttt{x2 = \&z[50];} \\
	4 & \texttt{x1 = malloc(...);} & \\
	5 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	6 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
	7 & \texttt{\hilight{brickred}{x1->foo = ...;}} & \\
	8 & \texttt{\hilight{olivegreen}{free}(x1);} \\
\end{tabular}
\caption{Goal interleaving of Figure~\ref{fig:overrun}. To ensure collision, the sequence of malloc calls which produce {\tt x1} and {\tt x2} must not be disrupted.}
\label{fig:overrun-goal}
\end{figure}

% TODO: Replace this with some real discussion.

%{\bf Being Owned.}
%The second best thing I can think to do is say, put "speculative" PPs on the end of malloc, and enable them only when that malloc is involved in a FRM situtation. Then, measure among all FRM sitations (gs12642/landslide/pldi/p2-live/frms) how much bigger the state spaces get (and whether that affects our bugfinding ability/cputimes).
%
%
%The first best thing I can think to do is to argue that this case doesn't disrupt soundness because the original model we were working with was already unsound. If the other interleaving ("the best dpor could find") occurred first, dpor would not identify a memory conflict at all, and would not reorder to find the original interleaving (with the FRM false pos) at all. this is because dpor ignores malloc's internal accesses from the shm conflict relation.

what we are trying to prove is that, if we START WITH a sound dpor, and add this FRM-elimination, you end up with a sound dpor. BUT, the original one was not sound with respect to this bug to begin with.

then you can simply point out that if you want dpor to be sound wrt this bug, you have to put a PP on the end of malloc (other spots, beginning of malloc and either end of free, are not needed), and also make the shm conflix relation account for the way malloc reordering can change the address collision issue.


\begin{lemma}
	asdfa
	\label{lem:leia} % "there is another"
\end{lemma}

%\subsection{Malloc with internal mutexes}
%
%First we assume that the malloc implementation is guarded by
%
%
%Mario man is very very hunger from not having enough plumming jobs, so his Quest for Eat and Dollars.
%
%
%\subsection{Malloc as a magic primitive}
%
%Actually, regardless of malloc's internal synchronization details, in virtually all cases we wish to avoid unnecessary PPs on its boundaries during MC, because unlike other uses of mutexes, it doesn't indicate any concurrent behaviour is going on.
%Much like the {\tt mx\_test} in our paper, the malloc implementation could itself be tested for concurrency bugs, but in all other cases,
%we drastically reduce the state space size by assuming it is correct and avoiding PPs on it, treating it instead as a ``magic primitive''.
%
%Hence, we provide another proof that does not require
%
%%\cite{landslide} % uncomment post-double-blind review
%
%This spells QED so we are done.
