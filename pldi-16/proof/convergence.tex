\section{Proof of Iterative Deepening convergence}

We seek to prove that, given enough time, Iterative Deepening offers the same coverage of thread interleavings that could be achieved by preempting at every single instruction.
We'll call the latter the {\em na\"{i}ve state space}, and call the condition of testing all its interleavings {\em convergence}.
(It could also be called soundness, from the perspective of viewing Iterative Deepening as a search re-ordering heuristic that doesn't miss any interleavings.)
Hence, our convergence statement is as follows:

\begin{theorem}[Total verification]
	If Iterative Deepening fully saturates its set of data-race PPs and completes all associated state spaces,
	it serves as a verification of all possible thread schedules of the given test program.
	\label{thm:totalverif}
\end{theorem}

The contrapositive statement offers more structure for an easier proof\footnote{
For the reader who likes to avoid non-constructive proofs, % \cite{vargomax}, % TODO: uncomment for camready/TR
note that we are using the constructive contrapositive direction:
Theorem~\ref{thm:convergence} is $A \rightarrow B$ and Theorem~\ref{thm:totalverif} is $\neg B \rightarrow \neg A$.}:

%DPOR + Iterative Deepening will eventually test every nonequivalent thread interleaving that would be exposed by preempting at every single instruction
\begin{theorem}[Convergence of Iterative Deepening]
	If a bug is exposed by an interleaving in the na\"{i}ve state space, Iterative Deepening will eventually test an equivalent interleaving which exposes the same bug.
	\label{thm:convergence}
\end{theorem}

\newcommand\ppnext[1]{\ensuremath{\mathsf{next}(#1)}}
\newcommand\ppinstr[1]{\ensuremath{\mathsf{instr}(#1)}}
\newcommand\ppothers[1]{\ensuremath{\mathsf{others}(#1)}}
\newcommand\pppfx[1]{\ensuremath{\mathsf{pfx}(#1)}}
\newcommand\conflicts[2]{\ensuremath{\mathsf{conflicts}(#1,#2)}}
\newcommand\pai{\ensuremath{p_{\alpha{}i}}}
\newcommand\tai{\ensuremath{t_{\alpha{}i}}}
Let
\[
	\mathcal{I} = \{(t_{\alpha{}1}, p_{\alpha{}1}), (t_{\beta{}1}, p_{\beta{}1}), ... (t_{\alpha{}n}, p_{\alpha{}n}), ...\}
\]
be an interleaving trace, where the element $(\tai, \pai)$ represents the $i$th transition $t$ of thread $\alpha$, and the associated preemption point $p$.
We will use the following notation:
\begin{itemize}
	\item $\ppnext{\pai}$ indicates the next transition by the same thread, $t_{\alpha{}(i+1)}$,
	\item $\ppinstr{\pai}$ indicates the first instruction executed during $t_{\alpha{}(i+1)}$. and
	\item $\ppothers{\pai}$ indicates the set of all transitions by other threads between $\tai$ and $t_{\alpha{}(i+1)}$.
	\item $\conflicts{t_\alpha,t_\beta}$ indicates the set of memory access pairs between $t_\alpha$ and $t_\beta$ such that among each pair, one access belongs to each thread $\alpha$ and $\beta$, the address is the same, and at least one is a write; i.e., precisely the shared memory conflict relation required by DPOR to determine dependent interleavings.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Equivalence of irrelevant PPs}

Iterative Deepening will not, of course, preempt on exactly the same instructions that an arbitrary naive interleaving would,
as it is only capable of preempting on data races and sync API boundaries.
Thus, our first task is to show that all naive interleavings have an equivalent interleaving with only data-race and sync API PPs.

\begin{definition}[Relevant preemption point]
	We say a PP $\pai$ is {\em relevant} if either $\ppnext{\pai}$ is a sync API boundary (including a voluntary yield),
	or if
	\[
		\conflicts{\ppothers{\pai}}{\ppinstr{\pai}} \ne \emptyset
	\]
	i.e., the instruction by thread $\alpha$ immediately after $\pai$ has a memory conflict with some other thread interleaved during $\pai$.
\end{definition}
\begin{definition}[Fully-relevant interleaving]
	An interleaving comprised only of relevant PPs.
\end{definition}

\begin{lemma}
	For any interleaving in the na\"{i}ve state space, there exists an equivalent interleaving which uses only relevant PPs.
	%data-race PPs and sync API PPs.
	\label{lem:equivalent}
\end{lemma}

\begin{proof}
	Let $\pai$ be the first irrelevant PP of a naive interleaving $\mathcal{I}$.
	We ask, did some thread among $\ppothers{\pai}$ conflict with any instruction from $\ppnext{\pai}$, even though there was no conflict with $\ppinstr{\pai}$?
	\begin{itemize}
			% rho for relevant.
		\item If $\conflicts{\ppothers{\pai}}{\ppnext{\pai}} \ne \emptyset$, or if $\tai$ contains a sync API boundary instruction that's not already a PP,
			then let $\rho$ be either the first instruction by $\ppnext{\pai}$ among the conflicts or the first sync API instruction, whichever comes first.
			Let $\pppfx{\rho}$ denote the instruction sequence between $\ppinstr{\pai}$ and $\rho$, including the former but not the latter.
			Now, we output the new interleaving:

			\begin{tabular}{lll}
				\\
				$\mathcal{I}' = \{...,$&$(\tai \cup \pppfx{\rho}, \pai'),$& \\
									   &$\ppothers{\pai},$& \\
					       &$(t_{\alpha{}(i+1)}) \setminus \pppfx{\rho}, p_{\alpha{}(i+1)}),$ & $ ...\}$ \\
				\\
			\end{tabular}

			In other words, we have simply reordered $\ppothers{\pai}$ to between $\pppfx{\rho}$ and $\rho$, removing the irrelevant $\pai$ and adding a new PP $\pai'$, which is relevant by the construction of $\rho$.
			We know it must be possible to reorder $\ppothers{\pai}$ to after $\alpha$'s execution because no synchronization is done during $\pppfx{\rho}$, hence the other threads' runnability cannot be affected.
			Likewise $\pppfx{\rho}$ is independent with $\ppothers{\pai}$, so by the soundness of DPOR \cite{dpor}, $\mathcal{I}' \equiv \mathcal{I}$.
		\item Otherwise, $\conflicts{\ppothers{\pai}}{\ppnext{\pai}} = \emptyset$, and no instructions among $\ppnext{\pai}$ are a sync API boundary.
			Then we output the new interleaving:
			\[
				\mathcal{I}' = \{..., (\tai \cup t_{\alpha(i+1)}, p_{\alpha(i+1)}), \ppothers{\pai},...\}
			\]
			In other words, we have reordered {\ppothers{\pai}} with the entire next transition by thread $\alpha$.
			We know this must be possible for the same reasons as above, and again, the transitions are independent, so $\mathcal{I}' \equiv \mathcal{I}$.
					       %&$(t_{\alpha{}(i+1)}) \setminus \pppfx{\rho}, p_{\alpha{}(i+1)}),$ & $ ...\}$ \\
	\end{itemize}
	This constitutes an algorithm for inductively converting (or removing) all irrelevant PPs to relevant ones.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Saturation of data-race PPs}

Now we must show that, starting from a sync-PP-only state space,
Iterative Deepening will eventually interleave threads sufficiently to expose all data races which are used as PPs in any buggy fully-relevant interleaving.
The challenge of this proof is that some data-race candidates are nondeterministic to find;
i.e., they may be hidden in an obscure control flow path which requires a prior preemption on a different data race to expose,
as shown in Figure~\ref{fig:nondet-dr}.
Hence, the maximal state space of statically-available sync API PPs will not necessarily uncover all possible data-race PPs;
Iterative Deepening may need to iterate through some data-race state spaces before finding certain nondeterministic races.

\begin{figure}[t]
	\small
	\begin{tabular}{rl}
	& \multicolumn{1}{c}{~\texttt{int x = 0, y = 0;~~~~~~~~~~~~~~~~}} \\
	& \multicolumn{1}{c}{\texttt{bool t1\_x = false, t1\_y = false;}} \\
	& \multicolumn{1}{c}{\texttt{bool t2\_x = false, t2\_y = false;}} \\
\\
		& Thread 1 (Thread 2 similar, with {\tt t1} and {\tt t2} vars swapped) \\
	1 & \texttt{\hilight{brickred}{x = x + 1;}} \\
	2 & \texttt{t1\_x = true;} \\
	3 & \texttt{// "if x raced"} \\
	4 & \texttt{if (x == 1 \&\& t2\_x) \{} \\
	5 & \texttt{~~~~\hilight{brickred}{y = y + 1;}} \\
	6 & \texttt{~~~~t1\_y = true;} \\
	7 & \texttt{~~~~// "if y raced"} \\
	8 & \texttt{~~~~if (y == 1 \&\& t2\_y) \{} \\
	9 & \texttt{~~~~~~~~panic();} \\
	10 & \texttt{~~~~\}} \\
	11 & \texttt{\}} \\
	\end{tabular}
	\caption{Not all data races will immediately be uncovered by interleaving threads around sync API PPs alone. Here, preempting during the race on line 1 is necessary to force the program into the control flow which can race on line 5.}
	\label{fig:nondet-dr}
\end{figure}

\begin{definition}[Reachable data race]
A data race candidate which will be identified by a MC configured to preempt only on locking API boundaries,
or transitively also configured to use data-race PPs of other
%already
reachable data races.
\end{definition}

\begin{definition}[Reachable preemption point]
A PP $\pai$ such that either $\ppinstr{\pai}$ is part of a reachable data race, or a sync API boundary.
\end{definition}

%%% weird backwards-induction thingie i came up with at the airport that doesn't work
%\begin{lemma}
%	Given a fully-relevant interleaving
%	\[
%		\mathcal{I} = \{ ..., (\tai,\pai), \ppothers{\pai}, (t_{\alpha(i+1)},p_{\alpha(i+1)}), ... \}
%	\]
%	if $\pai$ is a data-race PP, and the all PPs in the interleaving prefix
%	\[
%		\mathcal{J} = \{ ..., (\tai \cup t_{\alpha(i+1)}',p_{\alpha(i+1)}'), \ppothers(\pai)' \}
%	\]
%	are reachable, then $\pai$ is reachable.
%	\label{lem:coalesce}
%\end{lemma}
%
%Note here that in $\mathcal{J}$, some instructions of $t_{\alpha(i+1)}$ may change because they were reordered with $\ppothers(\pai)$;
%i.e., $\ppinstr(\pai)$ may not necessarily be the only site of thread communication,
%and some other conflicts may cause $t_{\alpha(i+1)}$ to behave differently.
%Hence we have labelled it $t_{\alpha(i+1)}'$, and similar for thread $\alpha$'s next PP.
%Nevertheless, the first instruction of $t_{\alpha(i+1)}'$ must still be the same as $\ppinstr{\pai}$.

\begin{lemma}
	All PPs of any fully-relevant interleaving are reachable.
	\label{lem:saturation}
\end{lemma}

\newcommand\pbh{\ensuremath{p_{\beta{}h}}}
\newcommand\paj{\ensuremath{p_{\alpha{}j}}}
\newcommand\pbk{\ensuremath{p_{\beta{}k}}}
\newcommand\tbh{\ensuremath{t_{\beta{}h}}}
\newcommand\tgk{\ensuremath{t_{\gamma{}k}}}
\newcommand\tgka{\ensuremath{t_{\gamma{}k1}}}
\newcommand\tgkb{\ensuremath{t_{\gamma{}k2}}}
\newcommand\tdl{\ensuremath{t_{\delta{}l}}}
\newcommand\coalesce[1]{\ensuremath{\mathsf{coalesce}(#1)}}

\begin{proof}
Let $\mathcal{I} = \{(t_{\alpha{}1}, p_{\alpha{}1}), ...\}$ be the fully-relevant interleaving and PP sequence in the premise of the lemma which exposed a bug.
We proceed by inducting on the PPs according to the order of their preemptions.
(Note that this is not necessarily the same as the order of the racing instructions $\ppinstr\pai$, which occur in $\ppnext\pai$, not in \tai.)
For both the base case and inductive step, we know (vacuously, for the former) that for each other PP $\pbh$ with $\tbh \prec \tai \in \mathcal{I}$, $\pbh$ is reachable.
We must show that a data race involving $\ppinstr\pai$
is reachable, and we are not allowed to use $\pai$ until we find the data race between $\ppinstr\pai$ and $\ppothers\pai$.

Consider the alternate interleaving prefix:
\[
	\mathcal{I}' = \{..., (\tai \cup \ppnext\pai', \paj), \ppothers\pai' \}
\]
where we have reordered $\ppnext\pai$ to before the execution of $\ppothers\pai$.
Here, $\paj$ is the first sync API PP in $\alpha$ after $\pai$ (as $p_{\alpha(i+1)}$ may be a not-yet-reachable data race PP),
and $\ppnext\pai'$ may include transitions of $\alpha$ beyond $\ppnext\pai$ itself.
%and for brevity, we will abbreviate the union of transitions as $\tak$.
Then, $\ppothers\pai'$ are the other threads' transitions from our target interleaving.
except they may be altered by the presence of some {\em other} data race in $\ppnext\pai'$ occurring after $\ppinstr\pai$.
Likewise, $\ppnext\pai'$ may be altered by some other data race in $\ppothers\pai'$.
The only certainty so far is that $\ppnext\pai'$ begins with $\ppinstr\pai$.

It would be straightforward to show that any other data races in $\ppnext\pai'$, which would be discovered in this interleaving,
could be reordered to after $\ppothers\pai'$,
eventually transforming $\ppnext\pai'$ to contain no conflicting memory accesses but $\ppinstr\pai$ itself.
Unfortunately, $\mathcal{I}'$ is not necessarily reachable, as $\ppothers\pai'$ still includes any data-race PPs from $\ppothers\pai$,
which were ordered after $\pai$ in $\mathcal{I}$ and hence not covered by the inductive assumption.
Hence, we must perform the same ``coalescing'' for each thread in $\ppothers\pai'$ that we did for $\alpha$,
which we will abbreviate:
\[
	\mathcal{I}'' = \{..., (\tai \cup \ppnext\pai', \paj), \coalesce{\ppothers\pai'} \}
\]
For each other thread $\beta$, $\coalesce{\ppothers\pai'}$ will contain a single transition,
starting with the first instruction of $\beta$'s corresponding transition in $\ppothers\pai$,
and ending with the next sync API PP in $\beta$, which we'll call $\pbk$.
It follows from the inductive hypothesis (which covers the prefix indicated by ``$...$''),
and from sync API PPs being reachable by definition,
that $\mathcal{I''}$ is reachable.

Again, the only certainly-executed instruction by any thread after $\tai$ is $\ppinstr\pai$.
It is even possible that neither $\ppinstr\pai$ nor any other instruction by thread $\alpha$ will conflict with any other thread,
until a different data race PP between two other threads is discovered,
as shown in Figure~\ref{fig:threethreads}.

\begin{figure}[t]
	TODO % TODO
	\caption{In this example, even though thread 1's data-race PP must occur first in a buggy interleaving, it cannot be reached until after Iterative Deepening first reaches the later-occurring data-race PP between threads 2 and 3.}
	\label{fig:threethreads}
\end{figure}

Now, we show by induction that a data race on $\ppinstr\pai$ will be reachable.
We assume that a state space $\mathcal{S}$ containing $\mathcal{I}''$,
plus $n$ unique data race PPs among $\ppnext\pai'$ and $\ppothers\pai$,
will be reachable.
(In the base case, the number of new data-race PPs is 0, and $\mathcal{I}''$'s reachability is justified above.)
We must show that in this state space, if the $\ppinstr\pai$ data race is not reachable,
a new unique data-race PP nevertheless will be.

By the definition of fully-relevant interleaving, it must be possible for some other thread $\beta$ to execute an instruction that conflicts with $\ppinstr\pai$.
%
If this conflict is not observed in $\mathcal{S}$,
it means that some preceding thread communication (involving any two threads $\gamma$ and $\delta$, either potentially the same or different as $\alpha$ or $\beta$) must exist to have suppressed it,
and that not all possible interleavings of that communication were tested in $\mathcal{S}$.
%
By the converse of our definition of DPOR, if a possible (conflicting, concurrent) thread interleaving is not tested,
% XXX: Handwave? I'm not entirely convinced by this step. How does it justify skipping all the way to the first possible "reachable" data race among the chain of PPs needed to expose \beta's communication with \ppinstr\pai?
then there must exist some transition with a necessary site of interleaving in the middle of it, rather than at its boundaries.

Let $\tgk$ be this transition, $\tgka$ and $\tgkb$ be the result of splitting at that site, and $\tdl$ be the communicating transition of the other thread.
%
If the interleaving $\{\tgka, \tdl', \tgkb'\}$ can produce a different program behaviour than $\{\tgka, \tgkb, \tdl\}$,
then again by the soundness of DPOR, $\tgkb$ and $\tdl$ must contain some shared memory conflict.
By the maximal state space assumption, all sync API PPs are enabled, so the locks held by $\gamma$ cannot change during $\tgk$,
and if $\tdl$ can be reordered to the middle of $\tgk$, the locksets of $\gamma$ and $\delta$ cannot overlap,
and likewise there is no sync-enforced MHB relation.
Hence the memory conflict between $\tdl$ and $\tgkb$ will be identified as a data-race.
Because $\tgk$ was split such that the first instruction of $\tgkb$ was not previously a PP, the data-race was not already enabled as a PP.

Hence either a data-race including $\ppinstr\pai$ will be identified,
or an infinite/nonterminating sequence of other unique data-race PPs will be identified,
but by the halting assumption, this would constitute an infinite loop bug, which is sufficient.
(Alternatively, for any program with a finitely-sized instruction listing, the number of unique instruction pairs is finite.)
This finishes our inner induction.
Hence $\pai$ is reachable, finishing our outer induction.
Hence all PPs in $\mathcal{I}$ are reachable.
\end{proof}

%%%%%%%%%%%%%%%%% this didn't work out
%We proceed by inducting on the PPs according to the order in which for each PP $\pai$, $\ppnext{\pai}$ appeared in the trace.
%Note that this is not necessarily the same as the order of the $\pai$s themselves in $\mathcal{I}$;
%i.e., it is the order of the racy instructions rather than the order of their immediately preceding preemptions\footnote{
%Why use this strange ordering, rather than simply inducting by the order of preemptions?
%Figure~\ref{fig:why-ppnext} shows why the first PP, ordered by earliest point of preemption, might not necessarily be the first reachable one.
%It is also true that the $\ppnext{\pai}$ order does not necessarily match the PPs' reachability dependence relation, but it is easier to cover the exception cases using this ordering rather than vice versa.}.
%
%\begin{figure}[t]
%	\caption{to do}
%	\label{fig:why-ppnext}
%\end{figure}
%%%% well, the way we do it, might not be the first reachable one either...
%
%\newcommand\pbj{\ensuremath{p_{\beta{}j}}}
%\newcommand\pgk{\ensuremath{p_{\gamma{}k}}}
%For both the base case and inductive step, we know (vacuously, for the former) that for each other PP $\pbj$ with $\ppnext{\pbj} \prec \ppnext{\pai} \in \mathcal{I}$, $\pbj$ is reachable.
%To show $\pai$ is reachable, the proof has two parts.
%First, we must handle any preceding data-race PPs $\pgk$ with $\ppnext{\pai} \prec \ppnext{\pgk}$.
%Second, we must show that when {\pai} is removed, a data-race including $\ppinstr{\pai}$ will be identified.
%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Conclusion}

\setcounter{theorem}{1}
\begin{theorem}[Convergence of Iterative Deepening]
	If a bug is exposed by an interleaving in the na\"{i}ve state space, Iterative Deepening will eventually test an interleaving which exposes the same bug.
\end{theorem}

\begin{proof}
By Lemma~\ref{lem:equivalent}, there must be some equivalent fully-relevant interleaving.
%the na\"{i}ve interleaving must be equivalent to some interleaving built of data-race PPs and sync API PPs.
By Lemma~\ref{lem:saturation}, Iterative Deepening will eventually discover and enable all necessary data-race PPs, with sync API PPs being enabled by the maximal state space assumption\footnote{
		In the paper we noted that when a bug is found, \quicksand~cancels all superset state spaces, anticipating that they would find the same bug.
		Because we are concerned with verifying the absence of bugs, we say this also suffices for convergence, but for brevity, we will leave this condition implicit.}.
Then we simply lean on the soundness of DPOR~\cite{dpor} to guarantee finding the buggy interleaving within this state space.
\end{proof}
