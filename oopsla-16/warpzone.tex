\section{Discussion}
\label{sec:future}

In this section, we discuss \quicksand's limitations and opportunities for future improvement.

% TODO CAMREADY: Measure how much subset overlap there is.
{\bf Avoiding redundant work.}
When we extend a small state space with more PPs, the new state space is guaranteed to test a superset of interleavings compared to the old one.
Any interleaving which does not preempt threads on any of the new PPs will be repeated work.
%Because we prioritize completing small state spaces before extending them with more PPs,
%the superset state spaces we run later will repeat each branch of their already-completed subsets.
%
%We measured the proportion of repeated work among completed state spaces across our test suite;
%on average, {\bf \large 999\%} of the interleavings in each test were repeated, with some tests as high as {\bf \large 9999\%}.
This may make us slower than SSS-MC to find certain bugs,
for example, if both {\tt lock} and {\tt unlock} PPs together expose a bug, but not either alone.
%Similarly, when pursuing total verification (\sect{\ref{sec:totalverif}}),
%if the state space resulting from preempting on every instruction could be completed,
%an SSS-MC tool such as \cite{spin} might achieve that verification faster,
%as Iterative Deepening will test many subsets of data-race PPs first.
Predicting whether an upcoming interleaving has already been tested is not straightforward,
but we believe future implementations
%of Iterative Deepening
could incorporate cross-job memoization
to prune some or all such repeated work.
\revisionx{Prioritizing the maximal state space in particular could also improve completion times:
whenever the maximal job finishes with no new data-races, future implementations could immediately prune all subset jobs and declare a total verification.}

{\bf Finer-grained PP subsets.}
\quicksand~was able to partially guarantee safety for some PPs in 89\% of tests with too-large maximal state spaces.
However, in 4 cases, no more than the minimal state space could be verified,
and in 6 others, no state spaces were completed at all.
%Larger state spaces often result from finer-grained locking,
%which can indicate a more intricate concurrent algorithm or an unnecessarily complicated design.
%Such programs may require even more rigorous verification than a program with a single global lock.
%Hence these corner cases are important to consider for future work.
While we used {\tt within\_function} (\sect{\ref{sec:landslide}}) {\em statically} to restrict where PPs could arise in advance of the test,
%we envision
future
%Iterative Deepening
implementations could use this mechanism to {\em dynamically} subset PPs further,
making partial verification of larger tests possible.
%enabling partial verification of such large tests. % if need space
%Because our current implementation does not avoid repeated interleavings across state spaces,
%as discussed above,
%we were limited to a small number of very basic PP subsets to statically seed the exploration

\revision{
{\bf Integration with static data-race analysis.}
In \sect{\ref{sec:eval-sssmc}}, we evaluated SSS-MC's ability to find data-race-induced failures
by configuring a static predicate to preempt on any non-stack memory access.
This introduced hundreds of new PPs on each new test execution, with a prohibitive performance impact.
While this performance could be improved by
%relaxing the preemption strategy,
instead using a static or single-pass analysis to find data-race candidate PPs in advance \cite{portend},
this strategy sacrifices the soundness of the verification guarantee, as shown in \sect{\ref{sec:eval-dr}}.
However, \quicksand~itself could employ static data-race analysis \cite{racerx} in future work.
Statically-identified data race candidates could heuristically be included in our ``seed'' PP sets (\sect{\ref{sec:initial-pp}}),
enabling \quicksand~to focus on the most suspicious races immediately, rather than waiting for them to be identified after potentially many iterations of MC.
}


%{\bf Small test cases.}

{\bf Partial verification.}
%We are not the first to provide a partial verification guarantee when timing out on too-large state spaces (\sect{\ref{sec:eval-sssmc}}).
While we guarantee safety when using certain combinations of PPs (\sect{\ref{sec:eval-sssmc}}),
%Iterative Context Bounding
ICB
guarantees safety under no more than a certain number of preemptions \cite{chess-icb}.
%according to the maximum bound reached in the time limit.
%We imagine
These guarantees could each be useful to developers in different scenarios,
and future work could combine the two approaches to provide both at once.
One benefit of our technique is that {\tt within\_function} %-based Iterative Deepening (discussed above)
would enable expert developers to
%configure custom subsets of PPs they are most interested in verifying,
%according to which modules of a codebase they wish to test.
restrict Iterative Deepening to only the modules of a codebase they wish to test.

Likewise, when full verification is not computationally feasible,
some jobs with data-race PPs will time out.
We cannot guarantee those races are
%false positives or
benign, even though no bug was found.
In the ``Untested DR PPs'' column of Table~\ref{tab:drbugs}, we show how many such candidates we could not verify (32\%).
For a more formal treatment of these cases, we refer the reader to the {\em k-witness harmless} metric introduced by \cite{portend},
which could be combined with \quicksand~in future work.
% Future work: Add parallel DPOR so you can fill your spare CPUs when there are fewer than the max number of jobs.
