\section{Soundness}
\label{sec:soundness}

In this section we present two theorems concerning Iterative Deepening's correctness.
Our full proofs,
available at \cite{quicksand-soundness},
%{\em [submitted as supplementary material; will be cited as a tech report in the final version of the paper]}
discuss our assumptions explicitly and include more formal definitions and structure.

\revisionx{These proofs are built on a DPOR algorithm definition which assumes sequentially-consistent memory hardware,
as discussed in \sect{\ref{sec:overview-sssmc}}.
We also assume the Limited HB definition
for the data-race analysis, as discussed in
\sect{\ref{sec:overview-dr}}.
%leaving the case for precise HB to future work.
}

\renewcommand\proofname{Proof Sketch}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Convergence to Total Verification}
\label{sec:totalverif}

Although Iterative Deepening's main purpose is to heuristically choose the most effective PP subsets to test
when the maximal state space is too large,
some tests may be small enough that even their maximal state spaces could be completed in time.
For such tests, preempting on every shared memory access \cite{spin,inspect} would provide a total verification of all possible thread schedules, if it could complete in time.
In this section, we show that Iterative Deepening provides a verification of the same strength if it completes the state spaces associated with every discovered data-race PP.
%In other words, contrapositively,
%if it is possible to find a bug with any sequence of preemptions on any instruction whatsoever,
%an equivalent thread interleaving will be reachable using only data-race PPs and synchronization API PPs.
A proof sketch of the contrapositive statement follows.

\newcommand\ppnext[1]{\ensuremath{\mathsf{next}(#1)}}
\newcommand\ppinstr[1]{\ensuremath{\mathsf{instr}(#1)}}
\newcommand\ppothers[1]{\ensuremath{\mathsf{others}(#1)}}
\begin{theorem}[Convergence]
If a bug can be exposed by any thread interleaving possible by preempting on all instructions during a specific test,
Iterative Deepening will eventually test an equivalent interleaving which exposes the same bug.
	\label{thm:convergence}
\end{theorem}
\begin{proof}
The proof has two parts:
first, we show that preempting on data-racing instructions and synchronization API boundaries suffices to test all possible program behaviour;
second, we show that Iterative Deepening will eventually detect all such data races.
Given a PP $p$, let $\ppnext{p}$ denote the next transition after $p$ executed by the thread which ran immediately before $p$,
let $\ppinstr{p}$ denote the first instruction of $\ppnext{p}$,
and let $\ppothers{p}$ denote the transitions by other threads between $p$ and $\ppnext{p}$.

\begin{lemma}[Equivalence of non-data-race PPs]
For any thread interleaving possible by preempting on any instruction,
there exists an equivalent interleaving which uses only data-race PPs and synchronization API PPs.
	\label{lem:relevant}
\end{lemma}

Let $p$ be the first PP in the given interleaving such that $\ppinstr{p}$ is not a data race with $\ppothers{p}$ nor is a synchronization API boundary.
Because $\ppinstr{p}$ is not a synchronization boundary,
no lock can be held during $\ppothers{p}$ that was also held by the first thread across $p$.
Hence, because $\ppinstr{p}$ is not a data race, it cannot be a shared memory conflict with $\ppothers{p}$ at all.
Let $i$ be the first instruction among $\ppnext{p}$ which is such a conflict, or a synchronization boundary.
If $i$ is a shared memory conflict, it must be a data race, for the same reasoning as above.
We modify the input interleaving by reordering $\ppinstr{p}$ until $i$, not including $i$, to before $\ppothers{p}$.
By the soundness of DPOR \cite{dpor}, this is equivalent to the input interleaving.
In other words, we have transformed $p$ into $p'$ such that $\ppnext{p'} = i$, which is a data race or synchronization boundary.
All PPs in the input trace can be inductively converted in the same manner.

\begin{definition}[Reachability]
A data race candidate, and its associated PPs, are reachable if it will be identified by an MC configured to preempt only on already-reachable PPs.
\end{definition}
Initially, the statically-available synchronization API PPs are reachable. Reachability of data-race PPs is transitive.

\begin{lemma}[Saturation of data-race PPs]
	Given any interleaving comprising only data-race PPs and synchronization API PPs, all involved PPs are reachable.
	\label{lem:saturation}
\end{lemma}

We induct on the PPs according to the order of their preemptions.
Given that the interleaving prefix preceding some PP $p$ is reachable,
we require that either $p$ is reachable, or a new data race among $\ppothers{p}$ will be newly reachable. %, not previously reachable, is now reachable.
The latter condition suffices because in a finitely-sized codebase, there must be finitely many unique racing instruction pairs.
%, so induction on the number of new data-race PPs among $\ppothers{p}$ will make $p$ itself reachable.

First, we must ``coalesce'' away $p$, as well as any other not-yet-reachable PPs in $\ppothers{p}$.
Consider the alternate interleaving in which the first thread executes past $p$ until the first already-reachable PP,
then the other threads among $\ppothers{p}$ execute the same way.
This interleaving's PPs are all reachable, so a state space $\mathcal{S}$ containing it will be tested.

If $p$ is a not-yet-reachable data-race PP,
it must be possible for some other thread to execute a data-racing instruction with $\ppinstr{p}$.
If this conflict was observed in the state space containing our coalesced interleaving, we have reached $p$.
Otherwise, we appeal to the soundness of DPOR:
If a program behaviour is possible by interleaving threads at the boundaries of the given transitions,
it will be tested in the containing state space.
By contrapositive, to expose this behaviour, one or more preemptions must occur in the middle of some transition, rather than at the boundaries.

We now show by contradiction there cannot be {\em multiple} data-race PPs which must all be enabled before either data race can be identified.
Assume there does not exist a single transition $t_1 \in \mathcal{S}$ which alone can be split into $\{t_1',t_1''\}$ by a PP $q$,
such that another thread's concurrent transition $t_2$ conflicts with $t_1''$.
By the soundness of DPOR, because all $t_2$s are independent with $t_1''$, $\mathcal{S} \equiv \mathcal{S} \cup q$.
Replacing $\mathcal{S}$ with $\mathcal{S} \cup q$ in the above assumption shows that no {\em pair} of new $q$s would expose new program behaviour, and inductively, no set of $q$s of any size, which contradicts the previous paragraph.

Hence, a single new not-yet-reachable data race is reachable in $\mathcal{S}$. Hence $p$ will be reached.
\\

To conclude,
for any possible interleaving, Lemma \ref{lem:relevant} provides an equivalent one with only data-race and synchronization PPs,
and Lemma \ref{lem:saturation} proves all involved PPs are reachable.
Hence, Iterative Deepening will eventually test a state space containing the equivalent buggy interleaving.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Suppressing ``Malloc-Recycle'' False Positives}
\label{sec:recycle}

We identify a particular class of false positive data-race candidates \revisionx{under Limited HB} in which the associated memory was recycled by re-allocation between the two accesses.
Figure~\ref{fig:recycle} shows a common code pattern and interleaving which can expose such behaviour.
If the {\tt malloc} on line 4 returns the same address passed to {\tt free} on line 2, then lines 1 and 7 will be flagged as a \revision{potential}~data race.
We call this a {\em malloc-recycle data race \revision{candidiate}}.
To the human eye, this is obviously a false positive: reordering lines 4-7 before lines 1-2 will change {\tt malloc}'s return value, causing {\tt x} and {\tt y} to no longer collide.
Here, Thread 2's logic usually corresponds to an initialization pattern \cite{eraser}, but for generality we have added a {\tt publish} action on line 6.

%However,
When limited to a single test execution, suppressing any data race \revision{candidate}~matching this pattern is unsound.
Consider the more unusual program in Figure~\ref{fig:recycle-bug},
in which the memory is recycled the same way, but the racing access's address is not tied to {\tt malloc}'s return value.
Here, reordering lines 6-7 before line 3 will allow {\tt x} and {\tt x2} to race.
\revisionx{Such collisions could be avoided with a hacked allocator which never recycles memory, but this could unacceptably impact performance in {\tt malloc}-heavy tests.}

\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& \multicolumn{2}{c}{\texttt{struct x \{ int foo; int baz; \} *x;}} \\
	& \multicolumn{2}{c}{\texttt{struct y \{ int bar; \} *y;~~~~~~~~~~}} \\
	\\
	& {\bf Thread 1} & {\bf Thread 2} \\
	1 & \texttt{\hilight{brickred}{x->foo = ...;}} & \\
	2 & \texttt{\hilight{olivegreen}{free}(x);} \\
	3 & & \texttt{\hilight{commentblue}{// x's memory recycled}} \\
	4 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	5 & & \texttt{\hilight{commentblue}{// ...initialize...}}\\
	6 & & \texttt{publish(y);} \\
	7 & & \texttt{\hilight{brickred}{y->bar = ...;}} \\
\end{tabular}
\caption{A common execution pattern with {\tt malloc()} that produces false positive data race candidates.}
\label{fig:recycle}
\end{figure}
\begin{figure}[t]
	\small
\begin{tabular}{rll}
	& {\bf Thread 1} & {\bf Thread 2} \\
	1 & \texttt{publish(x);} & \\
	2 & \texttt{\hilight{brickred}{x->foo = ...;}} & \\
	3 & \texttt{\hilight{olivegreen}{free}(x);} \\
	4 & & \texttt{x2 = get\_published\_x();} \\
	5 & & \texttt{\hilight{commentblue}{// x's memory recycled}} \\
	6 & & \texttt{y~=~\hilight{olivegreen}{malloc}(sizeof *y);} \\
	7 & & \texttt{\hilight{brickred}{x2->foo = ...;}} \\
\end{tabular}
	\caption{If a single-pass \revision{Limited HB analysis}~discarded candidates matching the malloc-recycle pattern,
it would miss the bug in this adversarial program.}
\label{fig:recycle-bug}
\end{figure}

Fortunately, when data-race detection is combined with DPOR and Iterative Deepening, pruning all malloc-recycle candidates is sound, even considering adversarial programs such as Figure~\ref{fig:recycle-bug}.
This makes it unnecessary to verify such \revision{candidates}~by actively adding more preemptions,
achieving a potentially combinatorial reduction in how many state spaces we generate.
%Intuitively, we need not worry about cases such as Figure~\ref{fig:recycle-bug} because,
%should they be true races,
%DPOR will reorder threads sufficiently for the malloc-recycle pattern to disappear.
We provide a proof sketch below.

\begin{theorem}[Soundness of eliminating malloc-recycle candidates]
	If a malloc-recycle \revision{candidate}~is not a false positive,
%DPOR will reorder threads such that
DPOR will test an alternate thread interleaving in which
%either
the accesses can race without fitting the malloc-recycle pattern.
%, or a use-after-free bug will be reported immediately.
\end{theorem}

\begin{proof}
%By definition of the malloc-recycle pattern,
Any such program must contain an access $a_1$ by one thread T1,
followed by a {\tt free} and a {\tt malloc} possibly by either thread,
followed by an access $a_2$ by the other thread T2. % not depending on the result of the middle malloc.
Without loss of generality, we say that T1 performs the {\tt free} and T2 the subsequent {\tt malloc}. %; the other cases are similar.
We also assume the only way for the program to get pointers to heap memory is through {\tt malloc};
hence, there must also be some ``publish'' action $p$ by T1 which communicates the address to T2.
Because this is a true \revision{potential}~data race, $p$ must occur before $a_1$, as $a_2$ cannot be reordered before $p$.

We require that a PP will be identified during T1 between $p$ and $a_1$.
The publish action must involve some thread communication, whether through a shared data structure or message-passing API.
If locking or message-passing is used, our set of hard-coded PPs suffices to provide a PP.
	Otherwise, $p$ (and the corresponding read by T2) will be a \revision{potential}~data race, although that may itself be a malloc-recycle \revision{candidate}.
In this case we use induction on the pointer chain leading to the shared address containing $p$:
in the base case, $p$ is communicated via global data or message-passing,
and in the inductive step, DPOR will reorder threads sufficiently to identify the PP on $p$.
Hence there will be a PP between $p$ and $a_1$ no matter the mode of communication.

With this PP, DPOR will reorder $a_2$ before $a_1$, while not changing $a_2$'s location.
As T2's {\tt malloc} now occurs before T1's {\tt free}, it will allocate different memory.
Hence $a_1$ and $a_2$ %will be in the same allocation;
can race without fitting the malloc-recycle pattern.
% Mario-man is very very hunger from not having enough plumming jobs, so his Quest for Eat and Dollars.
% This spells QED so we are done.
\end{proof}
\renewcommand\proofname{Proof}


We implemented a simple check in \landslide~to recognize the malloc-recycle pattern:
%We mechanically recognize when {\tt x} and {\tt y} correspond to different abstract allocations despite colliding on address,
%We implemented this check
%by adding a generation counter to \landslide's heap tracking:
%when tracking heap state,
each heap allocation is given a unique ID,
and when evaluating whether two heap accesses can race,
the IDs of their containing blocks must match.
Note that \revision{this proof does}~not require PPs on \revision{{\tt malloc}'s internal lock},
%the internal lock of {\tt malloc} or {\tt free},
which is an ideal candidate to ignore via {\tt without\_function} (\sect{\ref{sec:landslide}}) to reduce state space size.

\revision{This class of false positive is unique to heap-allocated memory among all ways threads could communicate.
By contrast, global memory has unlimited lifetime,
and message-passing primitives enforce an ordering which precludes the race. %(even under Limited HB).
Finally, note that as long as concurrent {\tt malloc} is implemented with an internal lock,
these false positives are of concern only under a Limited HB analysis (\sect{\ref{sec:overview-dr}}).
Nevertheless,
%our previous proof's
Theorem~\ref{thm:convergence}'s need for the Limited HB definition justifies our choice of it over full HB.
}

%%Because concurrent {\tt malloc} is often implemented with an internal lock, under a {\em pure} happens-before analysis,
%Note that under a {\em pure happens-before} analysis,
%these accesses are not considered concurrent % at all
%because of {\tt malloc}'s internal locking events,
%and would not result in such false positives.
%However, pure happens-before can miss many real bugs \cite{hybriddatarace,tsan},
%so in our context it is more appropriate to use the
%{\em limited happens-before} relation in a hybrid approach with lockset tracking.
%the hybrid approach combining lockset tracking and the {\em limited} happens-before relation is not vulnerable to false negatives,
